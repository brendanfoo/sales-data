{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f465500",
   "metadata": {},
   "source": [
    "# Project 2, Part 2, Parse Peak's sales JSON file into CSV files\n",
    "\n",
    "University of California, Berkeley\n",
    "\n",
    "Master of Information and Data Science (MIDS) program\n",
    "\n",
    "w205 - Fundamentals of Data Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6e20e",
   "metadata": {},
   "source": [
    "# Included Modules and Packages\n",
    "\n",
    "Code cell containing your includes for modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import json\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c8869",
   "metadata": {},
   "source": [
    "# Supporting code\n",
    "\n",
    "Code cells containing any supporting code, such as connecting to the database, any functions, etc.  \n",
    "\n",
    "Remember you can freely use any code from the labs. You do not need to cite code from the labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# function to run a select query and return rows in a pandas dataframe\n",
    "# pandas puts all numeric values from postgres to float\n",
    "# if it will fit in an integer, change it to integer\n",
    "#\n",
    "\n",
    "def my_select_query_pandas(query, rollback_before_flag, rollback_after_flag):\n",
    "    \"function to run a select query and return rows in a pandas dataframe\"\n",
    "    \n",
    "    if rollback_before_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    if rollback_after_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    # fix the float columns that really should be integers\n",
    "    \n",
    "    for column in df:\n",
    "    \n",
    "        if df[column].dtype == \"float64\":\n",
    "\n",
    "            fraction_flag = False\n",
    "\n",
    "            for value in df[column].values:\n",
    "                \n",
    "                if not np.isnan(value):\n",
    "                    if value - math.floor(value) != 0:\n",
    "                        fraction_flag = True\n",
    "\n",
    "            if not fraction_flag:\n",
    "                df[column] = df[column].astype('Int64')\n",
    "    \n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    user = \"postgres\",\n",
    "    password = \"ucb\",\n",
    "    host = \"postgres\",\n",
    "    port = \"5432\",\n",
    "    database = \"postgres\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_read_csv_file(file_name, limit):\n",
    "    \"read the csv file and print only the first limit rows\"\n",
    "    \n",
    "    csv_file = open(file_name, \"r\")\n",
    "    \n",
    "    csv_data = csv.reader(csv_file)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for row in csv_data:\n",
    "        i += 1\n",
    "        if i <= limit:\n",
    "            print(row)\n",
    "            \n",
    "    print(\"\\nPrinted \", min(limit, i), \"lines of \", i, \"total lines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_recursive_print_json(j, level = -1):\n",
    "    \"given a json object print it\"\n",
    "    \n",
    "    level += 1\n",
    "    \n",
    "    spaces = \"    \"\n",
    "    \n",
    "    if type(j) is dict:\n",
    "        dict_2_list = list(j.keys())\n",
    "        for k in dict_2_list:\n",
    "            print(spaces * level + k)\n",
    "            my_recursive_print_json(j[k], level)\n",
    "            \n",
    "    elif type(j) is list:\n",
    "        for (i, l) in enumerate(j):\n",
    "            print(spaces * level + \"[\" + str(i) + \"]\")\n",
    "            my_recursive_print_json(l, level)\n",
    "                  \n",
    "    else:\n",
    "        print(spaces * level + \"value:\", str(j))\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa274c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_read_nested_json(file_name):\n",
    "    \"given a file of json, read it and parse it meaningfully\"\n",
    "    \n",
    "    f = open(file_name, \"r\")\n",
    "    \n",
    "    j = json.load(f)\n",
    "    \n",
    "    f.close\n",
    "    \n",
    "    my_recursive_print_json(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e6beed",
   "metadata": {},
   "source": [
    "# 2.2.1 Recursive walk of Peak's sales JSON file to help understand the structure\n",
    "\n",
    "Peak has sent AGM a nested JSON file of sales data for October 3, 2020.  We need to first understand the structure of this file so we can parse it into CSV files to load into staging tables.\n",
    "\n",
    "Use the function my_read_nested_json() which calls my_recursive_print_json() to take a recursive walk of the nested JSON file peak_sales_2020_10_03.json to help understand the structure.  These functions are from the lab, and are included above for your convenience.\n",
    "\n",
    "Note: This will display a lot of output.  When running in Jupyter Notebook, the output will display in a scroll box.  When you look at it in GitHub in a web browser, it will be very long.  This is ok.\n",
    "\n",
    "### Please take some time to study the structure until you understand it.  Understanding the structure will make it much easier to write the parsing code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63b767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc4e9dd0",
   "metadata": {},
   "source": [
    "# 2.2.2 Parse Peak's nested JSON sales file into CSV files\n",
    "\n",
    "Write Python code to parse Peak's nested JSON sales file, peak_sales_2020_10_03.json, into CSV files.\n",
    "\n",
    "The first line of each CSV file should be a list of fields as specified below.\n",
    "\n",
    "Do NOT sort them.  Keep the csv data rows in the same order as the data appears in the JSON file.\n",
    "\n",
    "Do NOT remove duplicates.\n",
    "\n",
    "peak_sales.csv\n",
    "* sale_id - this is Peak's sale_id (NOT AGM's sale_id)\n",
    "* sale_date\n",
    "* sub_total - this should equal the sum of line item quantity x 12, however always use the data from the JSON file, as we will validate it later\n",
    "* tax - this should always be 0 as our items are tax exempt, however always use the data from the JSON file, as we will validate it later\n",
    "* total_amount - this should be equal to sub_total + tax, however always use the data from the JSON file, as we will validate it later\n",
    "\n",
    "peak_stores.csv\n",
    "* sale_id - we need this to be able to link this to peak_sales\n",
    "* location_id - this is Peak's location_id (NOT AGM's store_id)\n",
    "* name  \n",
    "* street \n",
    "* city \n",
    "* state \n",
    "* zip \n",
    "\n",
    "peak_customers.csv\n",
    "* sale_id - we need this to be able to link this to peak_sales\n",
    "* customer_id - this is Peak's customer_id (NOT AGM's customer_id)\n",
    "* first_name\n",
    "* last_name\n",
    "* street\n",
    "* city\n",
    "* state\n",
    "* zip\n",
    "\n",
    "peak_line_items.csv\n",
    "* sale_id - we need this to be able to link this to peak_sales\n",
    "* line_item_id - you will need to sequentially number them within each sale starting with 1, each new sale will start over at 1\n",
    "* product_id - this is Peak's product ID (NOT AGM's product_id)\n",
    "* price - this should always be 12 as as all of our items are 12, however always use the data from the JSON file, as we will validate it later\n",
    "* quantity\n",
    "* taxable - this should always be 'N' as our items are not taxable, however always use the data from the JSON file, as we will validate it later\n",
    "\n",
    "\n",
    "After creating these CSV files, be sure and check them into your GitHub repo.\n",
    "\n",
    "You may use as many code cells as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c0fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35faf850",
   "metadata": {},
   "source": [
    "# 2.2.3 Display the CSV file peak_sales.csv\n",
    "\n",
    "Use the function my_read_csv_file() from the labs (with a limit of 10) to display the CSV file you just created:\n",
    "* peak_sales.csv\n",
    "\n",
    "For your convenience the function is provided above.\n",
    "\n",
    "The output should look similar to this:\n",
    "```\n",
    "['sale_id', 'sale_date', 'sub_total', 'tax', 'total_amount']\n",
    "['5763728874', '2020-10-03', '12', '0', '12']\n",
    "['5763729036', '2020-10-03', '72', '0', '72']\n",
    "['5763728904', '2020-10-03', '24', '0', '24']\n",
    "['5763728973', '2020-10-03', '96', '0', '96']\n",
    "['5763728757', '2020-10-03', '108', '0', '108']\n",
    "['5763729051', '2020-10-03', '144', '0', '144']\n",
    "['5763729153', '2020-10-03', '24', '0', '24']\n",
    "['5763728608', '2020-10-03', '96', '0', '96']\n",
    "['5763728696', '2020-10-03', '84', '0', '84']\n",
    "\n",
    "Printed  10 lines of  98 total lines.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecda74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e885e55",
   "metadata": {},
   "source": [
    "# 2.2.4 Display the CSV file peak_stores.csv\n",
    "\n",
    "Use the function my_read_csv_file() from the labs (with a limit of 10) to display the CSV file you just created:\n",
    "* peak_stores.csv\n",
    "\n",
    "For your convenience, the function is provided above. \n",
    "\n",
    "The output should look similar to this:\n",
    "\n",
    "```\n",
    "['sale_id', 'location_id', 'name', 'street', 'city', 'state', 'zip']\n",
    "['5763728874', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763729036', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728904', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728973', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728757', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763729051', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763729153', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728608', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "['5763728696', '12573', 'Acme Gourmet Meals', '3000 Telegraph Ave', 'Berkeley', 'CA', '94705']\n",
    "\n",
    "Printed  10 lines of  98 total lines.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e979ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4a2ef6a",
   "metadata": {},
   "source": [
    "# 2.2.5 Display the CSV file peak_customers.csv\n",
    "\n",
    "Use the function my_read_csv_file() from the labs (with a limit of 10) to display the CSV file you just created:\n",
    "* peak_customers.csv\n",
    "\n",
    "For your convenience, the function is provided above.\n",
    "\n",
    "The output should look similar to this:\n",
    "\n",
    "```\n",
    "['sale_id', 'customer_id', 'first_name', 'last_name', 'street', 'city', 'state', 'zip']\n",
    "['5763728874', '3728404', 'Darrelle', 'Dohrmann', '46 Farwell Terrace', 'Oakland', 'CA', '94609']\n",
    "['5763729036', '3729309', 'Moria', 'Greenwood', '8803 Delaware Crossing', 'Berkeley', 'CA', '94705']\n",
    "['5763728904', '3728508', 'Josiah', 'Hulett', '6755 Melby Plaza', 'Oakland', 'CA', '94612']\n",
    "['5763728973', '3728534', 'Gayle', 'MacGarrity', '286 Onsgard Center', 'Berkeley', 'CA', '94703']\n",
    "['5763728757', '3729188', 'Courtenay', 'Shirrell', '75 West Park', 'Emeryville', 'CA', '94608']\n",
    "['5763729051', '3729276', 'Christian', 'Anyene', '869 Transport Crossing', 'Berkeley', 'CA', '94707']\n",
    "['5763729153', '3729242', 'Linnell', 'Barr', '521 Fallview Alley', 'Oakland', 'CA', '94602']\n",
    "['5763728608', '3728705', 'Benedick', 'Staneland', '3852 Laurel Park', 'Berkeley', 'CA', '94704']\n",
    "['5763728696', '3729340', 'Lanni', 'Pickavant', '481 Moose Pass', 'Oakland', 'CA', '94609']\n",
    "\n",
    "Printed  10 lines of  98 total lines.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b7b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d92221c",
   "metadata": {},
   "source": [
    "# 2.2.6 Display the CSV file peak_line_items.csv\n",
    "\n",
    "Use the function my_read_csv_file() from the labs (with a limit of 10) to display the CSV file you just created:\n",
    "* peak_line_items.csv\n",
    "\n",
    "For your convenience, the function is provided above.\n",
    "\n",
    "The output should look similar to this:\n",
    "\n",
    "```\n",
    "['sale_id', 'line_item_id', 'product_id', 'price', 'quantity', 'taxable']\n",
    "['5763728874', '1', '42314680', '12', '1', 'N']\n",
    "['5763729036', '1', '42314677', '12', '1', 'N']\n",
    "['5763729036', '2', '42314682', '12', '3', 'N']\n",
    "['5763729036', '3', '42314684', '12', '2', 'N']\n",
    "['5763728904', '1', '42314680', '12', '1', 'N']\n",
    "['5763728904', '2', '42314684', '12', '1', 'N']\n",
    "['5763728973', '1', '42314677', '12', '2', 'N']\n",
    "['5763728973', '2', '42314680', '12', '2', 'N']\n",
    "['5763728973', '3', '42314682', '12', '2', 'N']\n",
    "\n",
    "Printed  10 lines of  353 total lines.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb4678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
